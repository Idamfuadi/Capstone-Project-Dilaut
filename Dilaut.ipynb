{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dilaut.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Idamfuadi/Capstone-Project-Dilaut/blob/ml/Dilaut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbeRInOmtu7w"
      },
      "source": [
        "#Dilaut - Bangkit Capstone Project\n",
        "A catalog fish prices application which contains current month price and price fishes prediction for next month. The core of our idea is to help fishermen to sell their catch directly to the community, and maintain price stability among the community. Hopefully, it would help by providing transparency of fish prices, so that fishermen are not trapped by the prices given by middlemen, especially in Gresik, Jawa Timur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7B6kln-sksF"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufdUzeUi52nT",
        "collapsed": true
      },
      "source": [
        "#load dataset\n",
        "data = pd.read_csv('Dilaut Dataset.csv')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89YtejFPHI6P"
      },
      "source": [
        "#filling NaN data\n",
        "median = data.median()\n",
        "data.fillna(median, inplace=True)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PMz9rPE6Fvy"
      },
      "source": [
        "dm = data.filter(['Mas'])\n",
        "dmas = dm.values\n",
        "training_dm_len = math.ceil(len(dmas) * .8)\n",
        "training_dm_len "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DozzuXW6Olq"
      },
      "source": [
        "#scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "scaled_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNz5McD26XRS"
      },
      "source": [
        "#create the training data set\n",
        "train_data = scaled_data[0:training_dm_len, :]\n",
        "\n",
        "#split the data into X_train and y_train dataset\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(3, len(train_data)):\n",
        "  X_train.append(train_data[i-3:i, 0])\n",
        "  y_train.append(train_data[i, 0])\n",
        "  if i <= 4:\n",
        "    print(X_train)\n",
        "    print(y_train)\n",
        "    print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceRBV0Oj6a_5"
      },
      "source": [
        "#convert the X_train and y_train to numpy arrays\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRQ9wTjQ7HIK"
      },
      "source": [
        "#reshape the data\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRkrt2WrAmCx"
      },
      "source": [
        "#create the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, return_sequences= True,activation='relu',input_shape =(X_train.shape[1], 1)))\n",
        "model.add(LSTM(25, return_sequences= False,activation='relu'))\n",
        "model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 64, activation = 'relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='mean_squared_error', optimizer='Adam')\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBHLn_aKwe-i"
      },
      "source": [
        "#train the model\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC-yVF9l1PNK"
      },
      "source": [
        "#create the testing data set\n",
        "test_data = scaled_data[training_dm_len - 3: , :]\n",
        "\n",
        "#split the data into X_testing and y_testing dataset\n",
        "X_test = []\n",
        "y_test = dmas[training_dm_len:, :]\n",
        "\n",
        "for i in range(3, len(test_data)):\n",
        "  X_test.append(test_data[i-3:i, 0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyE4JhwIFpUb"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWYD-pJMGQiy"
      },
      "source": [
        "X_test = np.array(X_test)\n",
        "X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MHvWJgjGSCe"
      },
      "source": [
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OOAmidNGTn3"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions = scaler.inverse_transform(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icDzuCi-GVOj"
      },
      "source": [
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFUXDDMkGW3L"
      },
      "source": [
        "train = dm[:training_dm_len]\n",
        "valid = dm[training_dm_len:]\n",
        "valid['Predictions'] = predictions\n",
        "plt.xlabel('Date')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3KpZrNxGZx6"
      },
      "source": [
        "valid"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}